{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking folder: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16\n",
      "========================================================================================================================\n",
      "Config                         Region                           cv_score     cv_std Path\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "sigma_0.2_factor_0.2_FACTOR_batch_16 Left_OFC                           0.7881     0.0126 /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16/sigma_0.2_factor_0.2_FACTOR_batch_16/2025-09-16/20-03-30_0/troiani_custom_embeddings/Left_OFC/test_values.json\n",
      "sigma_0.4_factor_0.4_FACTOR_batch_16 Left_OFC                           0.7849     0.0176 /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16/sigma_0.4_factor_0.4_FACTOR_batch_16/2025-09-16/20-03-33_0/troiani_custom_embeddings/Left_OFC/test_values.json\n",
      "sigma_0.6_factor_0.6_FACTOR_batch_16 Left_OFC                           0.7819     0.0073 /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16/sigma_0.6_factor_0.6_FACTOR_batch_16/2025-09-16/20-21-31_0/troiani_custom_embeddings/Left_OFC/test_values.json\n",
      "sigma_0.8_factor_0.8_FACTOR_batch_16 Left_OFC                           0.7904     0.0139 /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16/sigma_0.8_factor_0.8_FACTOR_batch_16/2025-09-16/20-22-06_0/troiani_custom_embeddings/Left_OFC/test_values.json\n",
      "sigma_1.0_factor_1.0_FACTOR_batch_16 Left_OFC                           0.7873     0.0150 /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16/sigma_1.0_factor_1.0_FACTOR_batch_16/2025-09-16/21-17-54_0/troiani_custom_embeddings/Left_OFC/test_values.json\n",
      "sigma_1.2_factor_1.2_FACTOR_batch_16 Left_OFC                           0.7898     0.0122 /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16/sigma_1.2_factor_1.2_FACTOR_batch_16/2025-09-16/21-18-40_0/troiani_custom_embeddings/Left_OFC/test_values.json\n",
      "sigma_1.4_factor_1.4_FACTOR_batch_16 Left_OFC                           0.7840     0.0164 /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16/sigma_1.4_factor_1.4_FACTOR_batch_16/2025-09-16/21-20-08_0/troiani_custom_embeddings/Left_OFC/test_values.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import sys\n",
    "\n",
    "root_dir = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SOr_left_UKB40_32_16\"\n",
    "\n",
    "# Match: <root>/<config>/<date>/<run>/troiani_custom_embeddings/<region>/test_values.json\n",
    "pattern = os.path.join(\n",
    "    root_dir,\n",
    "    \"*\",                      # config\n",
    "    \"*\",                      # date\n",
    "    \"*\",                      # run\n",
    "    \"troiani_custom_embeddings\",\n",
    "    \"*\",                      # region\n",
    "    \"test_values.json\"\n",
    ")\n",
    "\n",
    "json_files = sorted(glob.glob(pattern))\n",
    "if not json_files:\n",
    "    print(f\"No JSON files found under {root_dir}!\")\n",
    "    print(\"Pattern used was:\", pattern)\n",
    "    sys.exit(1)\n",
    "\n",
    "# Header\n",
    "print(f\"\\nChecking folder: {root_dir}\")\n",
    "print(\"=\"*120)\n",
    "print(f\"{'Config':<30} {'Region':<30} {'cv_score':>10} {'cv_std':>10} {'Path'}\")\n",
    "print(\"-\"*120)\n",
    "\n",
    "for jp in json_files:\n",
    "    # relpath from root_dir:\n",
    "    rel = os.path.relpath(jp, root_dir)\n",
    "    parts = rel.split(os.sep)\n",
    "    # parts == [ config, date, run, \"troiani_custom_embeddings\", region, \"test_values.json\" ]\n",
    "    config = parts[0]\n",
    "    region = parts[4]\n",
    "\n",
    "    # load JSON\n",
    "    try:\n",
    "        with open(jp) as f:\n",
    "            data = json.load(f)\n",
    "        cv_score = float(data.get(\"cv_score\", float(\"nan\")))\n",
    "        cv_std   = float(data.get(\"cv_std\",   float(\"nan\")))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {jp}: {e}\")\n",
    "        cv_score = cv_std = float(\"nan\")\n",
    "\n",
    "    print(f\"{config:<30} {region:<30} {cv_score:10.4f} {cv_std:10.4f} {jp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking folder: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SC-sylv_left_UKB40_32_16\n",
      "====================================================================================================\n",
      "Config                              Run             Avg Test R2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "sigma_0.2_factor_0.2_FACTOR_batch_16 19-37-44_0          0.5319\n",
      "sigma_0.4_factor_0.4_FACTOR_batch_16 19-40-08_0          0.5170\n",
      "sigma_0.6_factor_0.6_FACTOR_batch_16 19-55-38_0          0.5226\n",
      "sigma_0.8_factor_0.8_FACTOR_batch_16 19-55-37_0          0.5243\n",
      "sigma_1.0_factor_1.0_FACTOR_batch_16 19-57-56_0          0.5265\n",
      "sigma_1.2_factor_1.2_FACTOR_batch_16 19-59-31_0          0.5053\n",
      "sigma_1.4_factor_1.4_FACTOR_batch_16 20-00-06_0          0.5217\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root_dir = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/SC-sylv_left_UKB40_32_16\"\n",
    "\n",
    "print(f\"\\nChecking folder: {root_dir}\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Config':<35} {'Run':<15} {'Avg Test R2':>10}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "for config_name in sorted(os.listdir(root_dir)):\n",
    "    config_path = os.path.join(root_dir, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    # -- go into each date folder under this config --\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        # -- go into each run folder under that date --\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # finally locate the isomap embeddings directory\n",
    "            isomap_dir = os.path.join(run_path, \"hcp_isomap_custom_embeddings\")\n",
    "            if not os.path.isdir(isomap_dir):\n",
    "                continue\n",
    "\n",
    "            # gather R2 over dims 1â€“6\n",
    "            r2_values = []\n",
    "            for dim in range(1, 7):\n",
    "                json_path = os.path.join(\n",
    "                    isomap_dir,\n",
    "                    f\"Isomap_central_left_dim{dim}\",\n",
    "                    \"test_values.json\"\n",
    "                )\n",
    "                if os.path.isfile(json_path):\n",
    "                    try:\n",
    "                        with open(json_path, \"r\") as f:\n",
    "                            data = json.load(f)\n",
    "                        r2 = data.get(\"test_r2\", None)\n",
    "                        if r2 is not None:\n",
    "                            r2_values.append(r2)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {json_path}: {e}\")\n",
    "\n",
    "            # compute and print\n",
    "            if r2_values:\n",
    "                avg_r2 = sum(r2_values) / len(r2_values)\n",
    "                print(f\"{config_name:<35} {run_name:<15} {avg_r2:10.4f}\")\n",
    "            else:\n",
    "                print(f\"{config_name:<35} {run_name:<15} {'No valid R2':>10}\")\n",
    "\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted file saved to: /neurospin/dico/data/deep_folding/current/datasets/UkBioBank40/OCCIPITAL_left_BT_seed_1_sorted.csv_clusters_sorted.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the input file\n",
    "input_file = \"/neurospin/dico/data/deep_folding/current/datasets/UkBioBank40/OCCIPITAL_left_BT_seed_1.csv_clusters.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Check if 'cluster' column exists\n",
    "if \"cluster\" not in df.columns:\n",
    "    raise ValueError(\"The column 'cluster' was not found in the CSV file.\")\n",
    "\n",
    "# Sort by the 'cluster' column\n",
    "df_sorted = df.sort_values(by=\"cluster\")\n",
    "\n",
    "# Save the sorted DataFrame to a new file\n",
    "output_file = input_file.replace(\".csv\", \"_sorted.csv\")\n",
    "df_sorted.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Sorted file saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/OCCIPITAL_left_32/sigma_null_factor_1.0_batch_128/2025-07-29/14-03-45_0\n",
      "Removing: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/OCCIPITAL_left_32/sigma_null_factor_0.8_batch_128/2025-07-29/14-03-45_0\n",
      "Removing: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/OCCIPITAL_left_32/sigma_null_factor_0.6_batch_128/2025-07-29/14-03-45_0\n",
      "Removing: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/SOr_left_UKB40_32/sigma_null_factor_0.2_batch_128/2025-07-29/14-03-45_0\n",
      "Removing: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/SOr_left_UKB40_32/sigma_null_factor_0.4_batch_128/2025-07-29/14-03-45_0\n",
      "Removing: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/SOr_left_UKB40_32/sigma_null_factor_0.8_batch_128/2025-07-29/14-03-45_0\n",
      "Removing: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/SOr_left_UKB40_32/sigma_null_factor_0.6_batch_128/2025-07-29/14-03-45_0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "BASE = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume\"\n",
    "TARGET_DIR = \"14-03-45_0\"\n",
    "\n",
    "for root, dirs, files in os.walk(BASE):\n",
    "    if TARGET_DIR in dirs:\n",
    "        path = os.path.join(root, TARGET_DIR)\n",
    "        print(f\"Removing: {path}\")\n",
    "        shutil.rmtree(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking folder: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/LARGE_CINGULATE_right_UKB40_32\n",
      "============================================================\n",
      "Config                         Run               CV Score     CV Std\n",
      "------------------------------------------------------------\n",
      "sigma_0.01_factor_0.2_batch_128 10-04-30_0          0.7936     0.0636\n",
      "sigma_0.01_factor_0.2_batch_16 10-04-31_0          0.8729     0.0517\n",
      "sigma_0.01_factor_0.4_batch_128 10-04-30_0          0.7781     0.0656\n",
      "sigma_0.01_factor_0.4_batch_16 10-04-30_0          0.8697     0.0497\n",
      "sigma_0.01_factor_0.6_batch_128 10-04-30_0          0.7543     0.1078\n",
      "sigma_0.01_factor_0.6_batch_16 10-04-30_0          0.8693     0.0498\n",
      "sigma_0.01_factor_0.8_batch_128 10-04-30_0          0.7496     0.0535\n",
      "sigma_0.01_factor_0.8_batch_16 10-04-30_0          0.8821     0.0501\n",
      "sigma_0.01_factor_1.0_batch_128 10-04-29_0          0.7325     0.0917\n",
      "sigma_0.01_factor_1.0_batch_16 10-04-29_0          0.8322     0.0672\n",
      "sigma_0.01_factor_1.2_batch_128 10-04-30_0          0.7359     0.0948\n",
      "sigma_0.01_factor_1.2_batch_16 10-04-30_0          0.8717     0.0568\n",
      "sigma_0.01_factor_1.4_batch_128 10-04-30_0          0.7749     0.0715\n",
      "sigma_0.01_factor_1.4_batch_16 10-04-30_0          0.8504     0.0659\n",
      "sigma_0.05_factor_0.2_batch_128 10-04-30_0          0.7938     0.0382\n",
      "sigma_0.05_factor_0.2_batch_16 10-04-31_0          0.8864     0.0573\n",
      "sigma_0.05_factor_0.4_batch_128 10-04-30_0          0.7628     0.0627\n",
      "sigma_0.05_factor_0.4_batch_16 10-04-31_0          0.8807     0.0584\n",
      "sigma_0.05_factor_0.6_batch_128 10-04-30_0          0.6960     0.0707\n",
      "sigma_0.05_factor_0.6_batch_16 10-04-30_0          0.8543     0.0582\n",
      "sigma_0.05_factor_0.8_batch_128 10-04-30_0          0.7396     0.0847\n",
      "sigma_0.05_factor_0.8_batch_16 10-04-30_0          0.8661     0.0766\n",
      "sigma_0.05_factor_1.0_batch_128 10-04-30_0          0.7368     0.0670\n",
      "sigma_0.05_factor_1.0_batch_16 10-04-30_0          0.8652     0.0454\n",
      "sigma_0.05_factor_1.2_batch_128 10-04-30_0          0.8064     0.0630\n",
      "sigma_0.05_factor_1.2_batch_16 10-04-30_0          0.8414     0.0595\n",
      "sigma_0.05_factor_1.4_batch_128 10-04-30_0          0.7738     0.0823\n",
      "sigma_0.05_factor_1.4_batch_16 10-04-30_0          0.8603     0.0714\n",
      "sigma_null_factor_0.2_batch_128 10-04-30_0          0.7358     0.0774\n",
      "sigma_null_factor_0.2_batch_16 10-04-30_0          0.8497     0.0590\n",
      "sigma_null_factor_0.4_batch_128 10-04-30_0          0.7552     0.0441\n",
      "sigma_null_factor_0.4_batch_16 10-04-40_0          0.8521     0.0620\n",
      "sigma_null_factor_0.6_batch_128 10-04-40_0          0.7345     0.0951\n",
      "sigma_null_factor_0.6_batch_16 10-04-41_0          0.8293     0.0749\n",
      "sigma_null_factor_0.8_batch_128 10-04-41_0          0.7160     0.0802\n",
      "sigma_null_factor_0.8_batch_16 10-04-41_0          0.8456     0.0711\n",
      "sigma_null_factor_1.0_batch_128 10-04-39_0          0.8145     0.0649\n",
      "sigma_null_factor_1.0_batch_16 10-04-39_0          0.8672     0.0535\n",
      "sigma_null_factor_1.2_batch_128 10-04-39_0          0.7373     0.0588\n",
      "sigma_null_factor_1.2_batch_16 10-04-30_0          0.8608     0.0689\n",
      "sigma_null_factor_1.4_batch_128 10-04-30_0          0.7665     0.0698\n",
      "sigma_null_factor_1.4_batch_16 10-04-30_0          0.8486     0.0443\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root_dir = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume/LARGE_CINGULATE_right_UKB40_32\"\n",
    "\n",
    "print(f\"\\nChecking folder: {root_dir}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Config':<30} {'Run':<15} {'CV Score':>10} {'CV Std':>10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for config_name in sorted(os.listdir(root_dir)):\n",
    "    config_path = os.path.join(root_dir, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # point at the ACC_custom_embeddings/Right_PCS folder\n",
    "            acc_dir = os.path.join(run_path, \"ACC_custom_embeddings\", \"Right_PCS\")\n",
    "            json_path = os.path.join(acc_dir, \"test_values.json\")\n",
    "            if not os.path.isfile(json_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(json_path, \"r\") as f:\n",
    "                    data = json.load(f)\n",
    "                cv_score = data.get(\"cv_score\", None)\n",
    "                cv_std   = data.get(\"cv_std\",   None)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {json_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            if cv_score is not None and cv_std is not None:\n",
    "                print(f\"{config_name:<30} {run_name:<15} {cv_score:10.4f} {cv_std:10.4f}\")\n",
    "            else:\n",
    "                print(f\"{config_name:<30} {run_name:<15} {'No CV':>10} {'No CV':>10}\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/OCCIPITAL_left_16_16/batch_16_seed_128/2025-09-15/16-42-39_0/ukb40_FCLp_no_classiffier_random_embeddings/full_embeddings.csv â†’ /home/cb283697/Bureau/ST/batch_16_seed_128/full_embeddings.csv\n",
      "Copied /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/OCCIPITAL_left_16_16/batch_16_seed_212/2025-09-15/16-42-50_0/ukb40_FCLp_no_classiffier_random_embeddings/full_embeddings.csv â†’ /home/cb283697/Bureau/ST/batch_16_seed_212/full_embeddings.csv\n",
      "Copied /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/OCCIPITAL_left_16_16/batch_16_seed_42/2025-09-15/16-42-50_0/ukb40_FCLp_no_classiffier_random_embeddings/full_embeddings.csv â†’ /home/cb283697/Bureau/ST/batch_16_seed_42/full_embeddings.csv\n",
      "Copied /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/OCCIPITAL_left_16_16/batch_16_seed_48/2025-09-15/16-42-39_0/ukb40_FCLp_no_classiffier_random_embeddings/full_embeddings.csv â†’ /home/cb283697/Bureau/ST/batch_16_seed_48/full_embeddings.csv\n",
      "Copied /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/OCCIPITAL_left_16_16/batch_16_seed_75/2025-09-15/16-42-50_0/ukb40_FCLp_no_classiffier_random_embeddings/full_embeddings.csv â†’ /home/cb283697/Bureau/ST/batch_16_seed_75/full_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Root folder containing all the batch_32_seed_* configs\n",
    "root_dir = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/OCCIPITAL_left_16_16\"\n",
    "\n",
    "# Destination base in your home\n",
    "dst_base = \"/home/cb283697/Bureau/ST\"\n",
    "\n",
    "# Name of the file to copy\n",
    "target_file = \"full_embeddings.csv\"\n",
    "\n",
    "# Make sure the destination base exists\n",
    "os.makedirs(dst_base, exist_ok=True)\n",
    "\n",
    "for config_name in sorted(os.listdir(root_dir)):\n",
    "    # on ne garde que les dossiers batch_32_seed_*\n",
    "    if not config_name.startswith(\"batch_16_seed_\"):\n",
    "        continue\n",
    "\n",
    "    config_path = os.path.join(root_dir, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    # For each date folder under this batch\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        # For each run folder under that date\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # Path to the embedding output\n",
    "            embed_dir = os.path.join(\n",
    "                run_path,\n",
    "                \"ukb40_FCLp_no_classiffier_random_embeddings\"\n",
    "            )\n",
    "            if not os.path.isdir(embed_dir):\n",
    "                continue\n",
    "\n",
    "            src_path = os.path.join(embed_dir, target_file)\n",
    "            if not os.path.isfile(src_path):\n",
    "                continue\n",
    "\n",
    "            # Create a subfolder for this batch in the destination\n",
    "            dst_dir = os.path.join(dst_base, config_name)\n",
    "            os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "            dst_path = os.path.join(dst_dir, target_file)\n",
    "            try:\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "                print(f\"Copied {src_path} â†’ {dst_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to copy {src_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All contents from\n",
      "  /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume_seed/OCCIPITAL_left_32_16/residualized\n",
      "have been copied into\n",
      "  /home/cb283697/Bureau/volume-seed-res\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# === CONFIG ===\n",
    "SRC_DIR = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/volume_seed/OCCIPITAL_left_32_16/residualized\"\n",
    "DST_DIR = \"/home/cb283697/Bureau/volume-seed-res\"\n",
    "# =============\n",
    "\n",
    "def copy_contents(src: str, dst: str):\n",
    "    \"\"\"\n",
    "    Recursively copy all files and folders from src into dst.\n",
    "    Creates dst if it doesn't exist. Overwrites existing files of the same name.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(src):\n",
    "        raise FileNotFoundError(f\"Source directory not found: {src}\")\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        # compute relative path from SRC_DIR\n",
    "        rel_path = os.path.relpath(root, src)\n",
    "        # target directory under DST_DIR\n",
    "        target_dir = os.path.join(dst, rel_path) if rel_path != \".\" else dst\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "        # copy each file\n",
    "        for fname in files:\n",
    "            src_file = os.path.join(root, fname)\n",
    "            dst_file = os.path.join(target_dir, fname)\n",
    "            shutil.copy2(src_file, dst_file)\n",
    "\n",
    "    print(f\"All contents from\\n  {src}\\nhave been copied into\\n  {dst}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    copy_contents(SRC_DIR, DST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python3\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Root folder for the FCLp-subsc-FCLa-INSULA_left_32 configs\n",
    "# src_root = (\n",
    "#     \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/BT/\"\n",
    "#     \"FCLp-subsc-FCLa-INSULA_left_32_32\"\n",
    "# )\n",
    "\n",
    "# # Destination base for all full_embeddings.csv files\n",
    "# dst_root = (\n",
    "#     \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/\"\n",
    "#     \"Output/BT\"\n",
    "#     \"FCLP-embeddings\"\n",
    "# )\n",
    "\n",
    "# # Make sure the destination base exists\n",
    "# os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "# for config_name in sorted(os.listdir(src_root)):\n",
    "#     # only the batch_128 sigma_null_factor configs\n",
    "#     if not (config_name.startswith(\"sigma_null_factor\") and config_name.endswith(\"_batch_128\")):\n",
    "#         continue\n",
    "\n",
    "#     config_path = os.path.join(src_root, config_name)\n",
    "#     if not os.path.isdir(config_path):\n",
    "#         continue\n",
    "\n",
    "#     # Dive into each date/run under this config\n",
    "#     for date_name in sorted(os.listdir(config_path)):\n",
    "#         date_path = os.path.join(config_path, date_name)\n",
    "#         if not os.path.isdir(date_path):\n",
    "#             continue\n",
    "\n",
    "#         for run_name in sorted(os.listdir(date_path)):\n",
    "#             run_path = os.path.join(date_path, run_name)\n",
    "#             if not os.path.isdir(run_path):\n",
    "#                 continue\n",
    "\n",
    "#             # Look for the embeddings directory\n",
    "#             embed_dir = os.path.join(run_path, \"schiz_random_embeddings\")\n",
    "#             src_file = os.path.join(embed_dir, \"full_embeddings.csv\")\n",
    "#             if not os.path.isfile(src_file):\n",
    "#                 continue\n",
    "\n",
    "#             # Prepare destination subfolder for this config\n",
    "#             dst_config_dir = os.path.join(dst_root, config_name)\n",
    "#             os.makedirs(dst_config_dir, exist_ok=True)\n",
    "\n",
    "#             # Copy the file\n",
    "#             dst_file = os.path.join(dst_config_dir, \"full_embeddings.csv\")\n",
    "#             try:\n",
    "#                 shutil.copy2(src_file, dst_file)\n",
    "#                 print(f\"Copied: {src_file}\\n      â†’ {dst_file}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error copying {src_file}: {e}\")\n",
    "\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# === Configuration ===\n",
    "src_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/FCLp-subsc-FCLa-INSULA_left_32_16\"\n",
    ")\n",
    "dst_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL/\"\n",
    "    \"FCLP-embeddings\"\n",
    ")\n",
    "# ======================\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "for config_name in sorted(os.listdir(src_root)):\n",
    "    # Include all batch_32_seed_* configs\n",
    "    if not config_name.startswith(\"sigma_\"):\n",
    "        continue\n",
    "\n",
    "    config_path = os.path.join(src_root, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    # Dive into each date folder under this config\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        # Dive into each run folder\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # Look for the embeddings directory\n",
    "            embed_dir = os.path.join(run_path, \"schiz_random_embeddings\")\n",
    "            src_file  = os.path.join(embed_dir, \"full_embeddings.csv\")\n",
    "            if not os.path.isfile(src_file):\n",
    "                continue\n",
    "\n",
    "            # Prepare a subdirectory in dst_root for this config\n",
    "            dst_config_dir = os.path.join(dst_root, config_name)\n",
    "            os.makedirs(dst_config_dir, exist_ok=True)\n",
    "\n",
    "            # Copy the embeddings file\n",
    "            dst_file = os.path.join(dst_config_dir, \"full_embeddings.csv\")\n",
    "            try:\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "                print(f\"Copied: {src_file}\\n      â†’ {dst_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA_left_16_16/batch_16_seed_128/2025-09-17/18-46-16_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA-embeddings/batch_16_seed_128/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA_left_16_16/batch_16_seed_212/2025-09-17/18-58-25_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA-embeddings/batch_16_seed_212/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA_left_16_16/batch_16_seed_42/2025-09-17/18-31-43_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA-embeddings/batch_16_seed_42/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA_left_16_16/batch_16_seed_48/2025-09-17/18-43-52_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA-embeddings/batch_16_seed_48/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA_left_16_16/batch_16_seed_75/2025-09-17/18-34-11_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA-embeddings/batch_16_seed_75/full_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# === Configuration ===\n",
    "src_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA_left_16_16\"\n",
    ")\n",
    "dst_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/\"\n",
    "    \"INSULA-embeddings\"\n",
    ")\n",
    "# ======================\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "for config_name in sorted(os.listdir(src_root)):\n",
    "    # Include all batch_32_seed_* configs\n",
    "    if not config_name.startswith(\"batch_16\"):\n",
    "        continue\n",
    "\n",
    "    config_path = os.path.join(src_root, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    # Dive into each date folder under this config\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        # Dive into each run folder\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # Look for the embeddings directory\n",
    "            embed_dir = os.path.join(run_path, \"schiz_random_embeddings\")\n",
    "            src_file  = os.path.join(embed_dir, \"full_embeddings.csv\")\n",
    "            if not os.path.isfile(src_file):\n",
    "                continue\n",
    "\n",
    "            # Prepare a subdirectory in dst_root for this config\n",
    "            dst_config_dir = os.path.join(dst_root, config_name)\n",
    "            os.makedirs(dst_config_dir, exist_ok=True)\n",
    "\n",
    "            # Copy the embeddings file\n",
    "            dst_file = os.path.join(dst_config_dir, \"full_embeddings.csv\")\n",
    "            try:\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "                print(f\"Copied: {src_file}\\n      â†’ {dst_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# === Configuration ===\n",
    "src_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/INSULA_left_16_16\"\n",
    ")\n",
    "dst_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_HULL_test/\"\n",
    "    \"INSULA-embeddings\"\n",
    ")\n",
    "# ======================\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "for config_name in sorted(os.listdir(src_root)):\n",
    "    # Include all batch_32_seed_* configs\n",
    "    if not config_name.startswith(\"batch_16\"):\n",
    "        continue\n",
    "\n",
    "    config_path = os.path.join(src_root, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    # Dive into each date folder under this config\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        # Dive into each run folder\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # Look for the embeddings directory\n",
    "            embed_dir = os.path.join(run_path, \"schiz_random_embeddings\")\n",
    "            src_file  = os.path.join(embed_dir, \"full_embeddings.csv\")\n",
    "            if not os.path.isfile(src_file):\n",
    "                continue\n",
    "\n",
    "            # Prepare a subdirectory in dst_root for this config\n",
    "            dst_config_dir = os.path.join(dst_root, config_name)\n",
    "            os.makedirs(dst_config_dir, exist_ok=True)\n",
    "\n",
    "            # Copy the embeddings file\n",
    "            dst_file = os.path.join(dst_config_dir, \"full_embeddings.csv\")\n",
    "            try:\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "                print(f\"Copied: {src_file}\\n      â†’ {dst_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16/sigma_0.2_factor_0.2_FACTOR_batch_16/2025-09-15/16-42-11_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA-embeddings/sigma_0.2_factor_0.2_FACTOR_batch_16/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16/sigma_0.4_factor_0.4_FACTOR_batch_16/2025-09-15/16-42-11_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA-embeddings/sigma_0.4_factor_0.4_FACTOR_batch_16/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16/sigma_0.6_factor_0.6_FACTOR_batch_16/2025-09-15/16-42-12_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA-embeddings/sigma_0.6_factor_0.6_FACTOR_batch_16/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16/sigma_0.8_factor_0.8_FACTOR_batch_16/2025-09-15/16-42-12_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA-embeddings/sigma_0.8_factor_0.8_FACTOR_batch_16/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16/sigma_1.0_factor_1.0_FACTOR_batch_16/2025-09-15/16-42-12_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA-embeddings/sigma_1.0_factor_1.0_FACTOR_batch_16/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16/sigma_1.2_factor_1.2_FACTOR_batch_16/2025-09-15/16-42-11_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA-embeddings/sigma_1.2_factor_1.2_FACTOR_batch_16/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16/sigma_1.4_factor_1.4_FACTOR_batch_16/2025-09-15/16-42-50_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA-embeddings/sigma_1.4_factor_1.4_FACTOR_batch_16/full_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# INSULA=======================================================================================================================================================\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# === Configuration ===\n",
    "src_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_32_16\"\n",
    ")\n",
    "dst_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/\"\n",
    "    \"INSULA-embeddings\"\n",
    ")\n",
    "# ======================\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "for config_name in sorted(os.listdir(src_root)):\n",
    "    # Include all batch_32_seed_* configs\n",
    "    if not config_name.startswith(\"sigma_\"):\n",
    "        continue\n",
    "\n",
    "    config_path = os.path.join(src_root, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    # Dive into each date folder under this config\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        # Dive into each run folder\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # Look for the embeddings directory\n",
    "            embed_dir = os.path.join(run_path, \"schiz_random_embeddings\")\n",
    "            src_file  = os.path.join(embed_dir, \"full_embeddings.csv\")\n",
    "            if not os.path.isfile(src_file):\n",
    "                continue\n",
    "\n",
    "            # Prepare a subdirectory in dst_root for this config\n",
    "            dst_config_dir = os.path.join(dst_root, config_name)\n",
    "            os.makedirs(dst_config_dir, exist_ok=True)\n",
    "\n",
    "            # Copy the embeddings file\n",
    "            dst_file = os.path.join(dst_config_dir, \"full_embeddings.csv\")\n",
    "            try:\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "                print(f\"Copied: {src_file}\\n      â†’ {dst_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLp-subsc-FCLa-INSULA_left_16_16/batch_16_seed_128/2025-09-15/11-00-35_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLP-embeddings/batch_16_seed_128/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLp-subsc-FCLa-INSULA_left_16_16/batch_16_seed_212/2025-09-15/11-00-34_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLP-embeddings/batch_16_seed_212/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLp-subsc-FCLa-INSULA_left_16_16/batch_16_seed_42/2025-09-15/10-59-22_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLP-embeddings/batch_16_seed_42/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLp-subsc-FCLa-INSULA_left_16_16/batch_16_seed_48/2025-09-15/11-00-35_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLP-embeddings/batch_16_seed_48/full_embeddings.csv\n",
      "Copied: /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLp-subsc-FCLa-INSULA_left_16_16/batch_16_seed_75/2025-09-15/10-59-21_0/schiz_random_embeddings/full_embeddings.csv\n",
      "      â†’ /neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/FCLP-embeddings/batch_16_seed_75/full_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# INSULA_TEST ================================================================================================================================================\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# === Configuration ===\n",
    "src_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL/INSULA_left_16_16\"\n",
    ")\n",
    "dst_root = (\n",
    "    \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/SURFACE_TOTAL_test/\"\n",
    "    \"FCLP-embeddings\"\n",
    ")\n",
    "# ======================\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dst_root, exist_ok=True)\n",
    "\n",
    "for config_name in sorted(os.listdir(src_root)):\n",
    "    # Include all batch_32_seed_* configs\n",
    "    if not config_name.startswith(\"batch_16\"):\n",
    "        continue\n",
    "\n",
    "    config_path = os.path.join(src_root, config_name)\n",
    "    if not os.path.isdir(config_path):\n",
    "        continue\n",
    "\n",
    "    # Dive into each date folder under this config\n",
    "    for date_name in sorted(os.listdir(config_path)):\n",
    "        date_path = os.path.join(config_path, date_name)\n",
    "        if not os.path.isdir(date_path):\n",
    "            continue\n",
    "\n",
    "        # Dive into each run folder\n",
    "        for run_name in sorted(os.listdir(date_path)):\n",
    "            run_path = os.path.join(date_path, run_name)\n",
    "            if not os.path.isdir(run_path):\n",
    "                continue\n",
    "\n",
    "            # Look for the embeddings directory\n",
    "            embed_dir = os.path.join(run_path, \"schiz_random_embeddings\")\n",
    "            src_file  = os.path.join(embed_dir, \"full_embeddings.csv\")\n",
    "            if not os.path.isfile(src_file):\n",
    "                continue\n",
    "\n",
    "            # Prepare a subdirectory in dst_root for this config\n",
    "            dst_config_dir = os.path.join(dst_root, config_name)\n",
    "            os.makedirs(dst_config_dir, exist_ok=True)\n",
    "\n",
    "            # Copy the embeddings file\n",
    "            dst_file = os.path.join(dst_config_dir, \"full_embeddings.csv\")\n",
    "            try:\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "                print(f\"Copied: {src_file}\\n      â†’ {dst_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying {src_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR  = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/BT/OCCIPITAL_left_32_32\"\n",
    "AGE_CSV   = \"/neurospin/dico/data/deep_folding/current/datasets/UkBioBank40/log_thickness_surface_Age.csv\"\n",
    "COVARIATE = \"log_surface_total\"\n",
    "OUT_DIR   = os.path.join(BASE_DIR, \"residualized\")\n",
    "# ============\n",
    "\n",
    "def find_embedding_paths(base_dir):\n",
    "    for cfg in os.listdir(base_dir):\n",
    "        cfg_dir = os.path.join(base_dir, cfg)\n",
    "        if not os.path.isdir(cfg_dir): continue\n",
    "        for date in os.listdir(cfg_dir):\n",
    "            date_dir = os.path.join(cfg_dir, date)\n",
    "            if not os.path.isdir(date_dir): continue\n",
    "            for run in os.listdir(date_dir):\n",
    "                emb_dir = os.path.join(\n",
    "                    date_dir, run,\n",
    "                    \"ukb40_FCLp_no_classiffier_random_embeddings\"\n",
    "                )\n",
    "                emb_file = os.path.join(emb_dir, \"full_embeddings.csv\")\n",
    "                if os.path.isfile(emb_file):\n",
    "                    # flatten the run path into a single name\n",
    "                    rel = f\"{cfg}_{date}_{run}\"\n",
    "                    yield rel, emb_file\n",
    "\n",
    "def residualize(emb_df, cov_ser):\n",
    "    \"\"\"Regress out cov_ser from each column of emb_df.\"\"\"\n",
    "    X = cov_ser.values.reshape(-1, 1)\n",
    "    R = np.zeros_like(emb_df.values)\n",
    "    lm = LinearRegression()\n",
    "    for j in range(emb_df.shape[1]):\n",
    "        y = emb_df.iloc[:, j].values\n",
    "        lm.fit(X, y)\n",
    "        R[:, j] = y - lm.predict(X)\n",
    "    return pd.DataFrame(R, index=emb_df.index, columns=emb_df.columns)\n",
    "\n",
    "def main():\n",
    "    # load covariate\n",
    "    parts = pd.read_csv(AGE_CSV, index_col=0)\n",
    "    if COVARIATE not in parts.columns:\n",
    "        raise KeyError(f\"{COVARIATE} not in {AGE_CSV}\")\n",
    "    cov = parts[COVARIATE]\n",
    "\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    for rel, emb_path in find_embedding_paths(BASE_DIR):\n",
    "        emb = pd.read_csv(emb_path, index_col=0)\n",
    "\n",
    "        # intersect IDs and drop any NaN in the covariate\n",
    "        common = emb.index.intersection(cov.index)\n",
    "        cov_sub = cov.loc[common]\n",
    "        emb_sub = emb.loc[common]\n",
    "        valid = cov_sub.notna()\n",
    "        if valid.sum() == 0:\n",
    "            print(f\"[SKIP] {rel}: no valid covariate values\")\n",
    "            continue\n",
    "\n",
    "        emb_sub = emb_sub.loc[valid]\n",
    "        cov_sub = cov_sub.loc[valid]\n",
    "\n",
    "        # residualize\n",
    "        resid_df = residualize(emb_sub, cov_sub)\n",
    "\n",
    "        # write out\n",
    "        out_file = os.path.join(OUT_DIR, f\"{rel}_resid.csv\")\n",
    "        resid_df.to_csv(out_file)\n",
    "        print(f\"[OK] {rel} â†’ {out_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-->] Residualizing batch_32_seed_128\n",
      "[ SKIP ] batch_32_seed_128: no overlapping IDs or all covariate NaN\n",
      "[-->] Residualizing batch_32_seed_212\n",
      "[ SKIP ] batch_32_seed_212: no overlapping IDs or all covariate NaN\n",
      "[-->] Residualizing batch_32_seed_42\n",
      "[ SKIP ] batch_32_seed_42: no overlapping IDs or all covariate NaN\n",
      "[-->] Residualizing batch_32_seed_48\n",
      "[ SKIP ] batch_32_seed_48: no overlapping IDs or all covariate NaN\n",
      "[-->] Residualizing batch_32_seed_75\n",
      "[ SKIP ] batch_32_seed_75: no overlapping IDs or all covariate NaN\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# === CONFIG ===\n",
    "BASE_DIR  = \"/neurospin/dico/babdelghani/Runs/02_champollion_v1/Output/BT/FCLP-embeddings\"\n",
    "AGE_CSV   = \"/neurospin/dico/data/deep_folding/current/datasets/UkBioBank40/log_thickness_surface_Age.csv\"\n",
    "COVARIATE = \"log_surface_total\"\n",
    "OUT_DIR   = os.path.join(BASE_DIR, \"residualized\")\n",
    "# ============\n",
    "\n",
    "def find_embedding_paths(base_dir):\n",
    "    for cfg in sorted(os.listdir(base_dir)):\n",
    "        cfg_dir = os.path.join(base_dir, cfg)\n",
    "        if not os.path.isdir(cfg_dir):\n",
    "            continue\n",
    "        # recurse until we find full_embeddings.csv\n",
    "        for root, _, files in os.walk(cfg_dir):\n",
    "            if \"full_embeddings.csv\" in files:\n",
    "                yield cfg, os.path.join(root, \"full_embeddings.csv\")\n",
    "\n",
    "def residualize(emb_df, cov_ser):\n",
    "    X = cov_ser.values.reshape(-1, 1)\n",
    "    R = np.zeros_like(emb_df.values)\n",
    "    lm = LinearRegression()\n",
    "    for j in range(emb_df.shape[1]):\n",
    "        y = emb_df.iloc[:, j].values\n",
    "        lm.fit(X, y)\n",
    "        R[:, j] = y - lm.predict(X)\n",
    "    return pd.DataFrame(R, index=emb_df.index, columns=emb_df.columns)\n",
    "\n",
    "def main():\n",
    "    # 1) load and prefix covariate\n",
    "    parts = pd.read_csv(AGE_CSV, index_col=0)\n",
    "    if COVARIATE not in parts.columns:\n",
    "        raise KeyError(f\"Covariate '{COVARIATE}' not found in {AGE_CSV}\")\n",
    "    if not str(parts.index[0]).startswith(\"sub-\"):\n",
    "        parts.index = [\"sub-\" + str(i) for i in parts.index.astype(str)]\n",
    "    cov = parts[COVARIATE].astype(float)\n",
    "\n",
    "    # 2) make output dir\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    # 3) process every embedding file found\n",
    "    for cfg, emb_path in find_embedding_paths(BASE_DIR):\n",
    "        print(f\"[-->] Residualizing {cfg}\")\n",
    "        emb = pd.read_csv(emb_path, index_col=0)\n",
    "\n",
    "        # align IDs and drop NaNs\n",
    "        common = emb.index.intersection(cov.index)\n",
    "        emb_sub = emb.loc[common]\n",
    "        cov_sub = cov.loc[common].dropna()\n",
    "        emb_sub = emb_sub.loc[cov_sub.index]\n",
    "\n",
    "        if emb_sub.shape[0] == 0:\n",
    "            print(f\"[ SKIP ] {cfg}: no overlapping IDs or all covariate NaN\")\n",
    "            continue\n",
    "\n",
    "        # residualize\n",
    "        resid_df = residualize(emb_sub, cov_sub)\n",
    "\n",
    "        # save\n",
    "        out_file = os.path.join(OUT_DIR, f\"{cfg}_resid.csv\")\n",
    "        resid_df.to_csv(out_file)\n",
    "        print(f\"[   OK ] {cfg} â†’ {out_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

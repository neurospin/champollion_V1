{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2256916/3352108578.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "# from sklearn.model_selection import StratifiedGroupKFold\n",
    "import random\n",
    "import csv\n",
    "import glob\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.utils import (\n",
    "    _approximate_mode,\n",
    "    _safe_indexing,\n",
    "    check_random_state,\n",
    "    indexable,\n",
    "    metadata_routing,\n",
    ")\n",
    "\n",
    "from sklearn.utils.validation import _num_samples, check_array, column_or_1d\n",
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedGroupKFold_WithoutCheck(sklearn.model_selection._split.GroupsConsumerMixin, sklearn.model_selection._split._BaseKFold):\n",
    "    \"\"\"Stratified K-Fold iterator variant with non-overlapping groups.\n",
    "\n",
    "    This cross-validation object is a variation of StratifiedKFold attempts to\n",
    "    return stratified folds with non-overlapping groups. The folds are made by\n",
    "    preserving the percentage of samples for each class.\n",
    "\n",
    "    Each group will appear exactly once in the test set across all folds (the\n",
    "    number of distinct groups has to be at least equal to the number of folds).\n",
    "\n",
    "    The difference between :class:`~sklearn.model_selection.GroupKFold`\n",
    "    and :class:`~sklearn.model_selection.StratifiedGroupKFold` is that\n",
    "    the former attempts to create balanced folds such that the number of\n",
    "    distinct groups is approximately the same in each fold, whereas\n",
    "    StratifiedGroupKFold attempts to create folds which preserve the\n",
    "    percentage of samples for each class as much as possible given the\n",
    "    constraint of non-overlapping groups between splits.\n",
    "\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "\n",
    "    For visualisation of cross-validation behaviour and\n",
    "    comparison between common scikit-learn split methods\n",
    "    refer to :ref:`sphx_glr_auto_examples_model_selection_plot_cv_indices.py`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of folds. Must be at least 2.\n",
    "\n",
    "    shuffle : bool, default=False\n",
    "        Whether to shuffle each class's samples before splitting into batches.\n",
    "        Note that the samples within each split will not be shuffled.\n",
    "        This implementation can only shuffle groups that have approximately the\n",
    "        same y distribution, no global shuffle will be performed.\n",
    "\n",
    "    random_state : int or RandomState instance, default=None\n",
    "        When `shuffle` is True, `random_state` affects the ordering of the\n",
    "        indices, which controls the randomness of each fold for each class.\n",
    "        Otherwise, leave `random_state` as `None`.\n",
    "        Pass an int for reproducible output across multiple function calls.\n",
    "        See :term:`Glossary <random_state>`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.model_selection import StratifiedGroupKFold\n",
    "    >>> X = np.ones((17, 2))\n",
    "    >>> y = np.array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    >>> groups = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 7, 8, 8])\n",
    "    >>> sgkf = StratifiedGroupKFold(n_splits=3)\n",
    "    >>> sgkf.get_n_splits(X, y)\n",
    "    3\n",
    "    >>> print(sgkf)\n",
    "    StratifiedGroupKFold(n_splits=3, random_state=None, shuffle=False)\n",
    "    >>> for i, (train_index, test_index) in enumerate(sgkf.split(X, y, groups)):\n",
    "    ...     print(f\"Fold {i}:\")\n",
    "    ...     print(f\"  Train: index={train_index}\")\n",
    "    ...     print(f\"         group={groups[train_index]}\")\n",
    "    ...     print(f\"  Test:  index={test_index}\")\n",
    "    ...     print(f\"         group={groups[test_index]}\")\n",
    "    Fold 0:\n",
    "      Train: index=[ 0  1  2  3  7  8  9 10 11 15 16]\n",
    "             group=[1 1 2 2 4 5 5 5 5 8 8]\n",
    "      Test:  index=[ 4  5  6 12 13 14]\n",
    "             group=[3 3 3 6 6 7]\n",
    "    Fold 1:\n",
    "      Train: index=[ 4  5  6  7  8  9 10 11 12 13 14]\n",
    "             group=[3 3 3 4 5 5 5 5 6 6 7]\n",
    "      Test:  index=[ 0  1  2  3 15 16]\n",
    "             group=[1 1 2 2 8 8]\n",
    "    Fold 2:\n",
    "      Train: index=[ 0  1  2  3  4  5  6 12 13 14 15 16]\n",
    "             group=[1 1 2 2 3 3 3 6 6 7 8 8]\n",
    "      Test:  index=[ 7  8  9 10 11]\n",
    "             group=[4 5 5 5 5]\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The implementation is designed to:\n",
    "\n",
    "    * Mimic the behavior of StratifiedKFold as much as possible for trivial\n",
    "      groups (e.g. when each group contains only one sample).\n",
    "    * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
    "      ``y = [1, 0]`` should not change the indices generated.\n",
    "    * Stratify based on samples as much as possible while keeping\n",
    "      non-overlapping groups constraint. That means that in some cases when\n",
    "      there is a small number of groups containing a large number of samples\n",
    "      the stratification will not be possible and the behavior will be close\n",
    "      to GroupKFold.\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    StratifiedKFold: Takes class information into account to build folds which\n",
    "        retain class distributions (for binary or multiclass classification\n",
    "        tasks).\n",
    "\n",
    "    GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=5, shuffle=False, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "\n",
    "    def _iter_test_indices(self, X, y, groups):\n",
    "        # Implementation is based on this kaggle kernel:\n",
    "        # https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\n",
    "        # and is a subject to Apache 2.0 License. You may obtain a copy of the\n",
    "        # License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "        # Changelist:\n",
    "        # - Refactored function to a class following scikit-learn KFold\n",
    "        #   interface.\n",
    "        # - Added heuristic for assigning group to the least populated fold in\n",
    "        #   cases when all other criteria are equal\n",
    "        # - Swtch from using python ``Counter`` to ``np.unique`` to get class\n",
    "        #   distribution\n",
    "        # - Added scikit-learn checks for input: checking that target is binary\n",
    "        #   or multiclass, checking passed random state, checking that number\n",
    "        #   of splits is less than number of members in each class, checking\n",
    "        #   that least populated class has more members than there are splits.\n",
    "        rng = check_random_state(self.random_state)\n",
    "        y = np.asarray(y)\n",
    "        type_of_target_y = type_of_target(y)\n",
    "        allowed_target_types = (\"binary\", \"multiclass\")\n",
    "        if type_of_target_y not in allowed_target_types:\n",
    "            raise ValueError(\n",
    "                \"Supported target types are: {}. Got {!r} instead.\".format(\n",
    "                    allowed_target_types, type_of_target_y\n",
    "                )\n",
    "            )\n",
    "\n",
    "        y = column_or_1d(y)\n",
    "        _, y_inv, y_cnt = np.unique(y, return_inverse=True, return_counts=True)\n",
    "        # if np.all(self.n_splits > y_cnt):\n",
    "        #     raise ValueError(\n",
    "        #         \"n_splits=%d cannot be greater than the\"\n",
    "        #         \" number of members in each class.\" % (self.n_splits)\n",
    "        #     )\n",
    "        # n_smallest_class = np.min(y_cnt)\n",
    "        # if self.n_splits > n_smallest_class:\n",
    "        #     warnings.warn(\n",
    "        #         \"The least populated class in y has only %d\"\n",
    "        #         \" members, which is less than n_splits=%d.\"\n",
    "        #         % (n_smallest_class, self.n_splits),\n",
    "        #         UserWarning,\n",
    "        #     )\n",
    "        n_classes = len(y_cnt)\n",
    "\n",
    "        _, groups_inv, groups_cnt = np.unique(\n",
    "            groups, return_inverse=True, return_counts=True\n",
    "        )\n",
    "        y_counts_per_group = np.zeros((len(groups_cnt), n_classes))\n",
    "        for class_idx, group_idx in zip(y_inv, groups_inv):\n",
    "            y_counts_per_group[group_idx, class_idx] += 1\n",
    "\n",
    "        y_counts_per_fold = np.zeros((self.n_splits, n_classes))\n",
    "        groups_per_fold = defaultdict(set)\n",
    "\n",
    "        if self.shuffle:\n",
    "            rng.shuffle(y_counts_per_group)\n",
    "\n",
    "        # Stable sort to keep shuffled order for groups with the same\n",
    "        # class distribution variance\n",
    "        sorted_groups_idx = np.argsort(\n",
    "            -np.std(y_counts_per_group, axis=1), kind=\"mergesort\"\n",
    "        )\n",
    "\n",
    "        for group_idx in sorted_groups_idx:\n",
    "            group_y_counts = y_counts_per_group[group_idx]\n",
    "            best_fold = self._find_best_fold(\n",
    "                y_counts_per_fold=y_counts_per_fold,\n",
    "                y_cnt=y_cnt,\n",
    "                group_y_counts=group_y_counts,\n",
    "            )\n",
    "            y_counts_per_fold[best_fold] += group_y_counts\n",
    "            groups_per_fold[best_fold].add(group_idx)\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            test_indices = [\n",
    "                idx\n",
    "                for idx, group_idx in enumerate(groups_inv)\n",
    "                if group_idx in groups_per_fold[i]\n",
    "            ]\n",
    "            yield test_indices\n",
    "\n",
    "    def _find_best_fold(self, y_counts_per_fold, y_cnt, group_y_counts):\n",
    "        best_fold = None\n",
    "        min_eval = np.inf\n",
    "        min_samples_in_fold = np.inf\n",
    "        for i in range(self.n_splits):\n",
    "            y_counts_per_fold[i] += group_y_counts\n",
    "            # Summarise the distribution over classes in each proposed fold\n",
    "            std_per_class = np.std(y_counts_per_fold / y_cnt.reshape(1, -1), axis=0)\n",
    "            y_counts_per_fold[i] -= group_y_counts\n",
    "            fold_eval = np.mean(std_per_class)\n",
    "            samples_in_fold = np.sum(y_counts_per_fold[i])\n",
    "            is_current_fold_better = (\n",
    "                fold_eval < min_eval\n",
    "                or np.isclose(fold_eval, min_eval)\n",
    "                and samples_in_fold < min_samples_in_fold\n",
    "            )\n",
    "            if is_current_fold_better:\n",
    "                min_eval = fold_eval\n",
    "                min_samples_in_fold = samples_in_fold\n",
    "                best_fold = i\n",
    "        return best_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreCatatoes\n",
    "n_splits = 5\n",
    "n_test_splits = 0\n",
    "orb = pd.read_csv('/neurospin/dico/data/bv_databases/human/partially_labeled/orbital_patterns/PreCatatoes/OFC_sulcal_type_data_186-subjects_columns-renamed.csv', index_col=0, usecols=['participant_id', 'sex', 'type_OFC_G', 'type_OFC_D '])\n",
    "orb = orb.dropna()\n",
    "orb.columns=['Sex', 'Left', 'Right']\n",
    "orb.index.names = ['Subject']\n",
    "subset = pd.read_csv('/neurospin/dico/data/deep_folding/current/datasets/PreCatatoes/crops/2mm/S.Or./mask/Lskeleton_subject.csv')['Subject'].tolist()\n",
    "orb = orb.loc[subset]\n",
    "\n",
    "l = orb['Left'].tolist()\n",
    "for idx, elem in enumerate(l):\n",
    "    if elem=='I':\n",
    "        l[idx]=1\n",
    "    elif elem=='II':\n",
    "        l[idx]=2\n",
    "    elif elem=='III':\n",
    "        l[idx]=3\n",
    "    elif elem=='IV':\n",
    "        l[idx]=4\n",
    "orb['Left'] = l\n",
    "\n",
    "l = orb['Right'].tolist()\n",
    "for idx, elem in enumerate(l):\n",
    "    if elem=='I':\n",
    "        l[idx]=1\n",
    "    elif elem=='II':\n",
    "        l[idx]=2\n",
    "    elif elem=='III':\n",
    "        l[idx]=3\n",
    "    elif elem=='IV':\n",
    "        l[idx]=4\n",
    "orb['Right'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Left</th>\n",
       "      <th>Right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sex  Left  Right\n",
       "Subject                 \n",
       "101       F     1      2\n",
       "102       M     2      3\n",
       "103       M     4      2\n",
       "104       F     1      3\n",
       "105       M     2      2\n",
       "...      ..   ...    ...\n",
       "95        M     1      3\n",
       "96        F     3      1\n",
       "97        M     2      2\n",
       "98        M     3      2\n",
       "9         M     4      1\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIP\n",
    "n_splits=10\n",
    "n_test_splits = 2\n",
    "orb = pd.read_excel('/neurospin/dico/data/bv_databases/human/partially_labeled/FIP_patterns/IPS_labels_390.xlsx')\n",
    "orb = orb.dropna()\n",
    "orb.columns = ['Subject', 'Sex', 'Left', 'Right']\n",
    "orb = orb.set_index('Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_frequencies(df):\n",
    "    for right in df['Right'].unique():\n",
    "        for left in df['Left'].unique():\n",
    "            for sex in df['Sex'].unique():\n",
    "                freq = df.query(\"Right==@right and Left==@left and Sex==@sex\")\n",
    "                print(f\"{right}, {left}, {sex}: {len(freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 0, M: 44\n",
      "1, 0, F: 74\n",
      "1, 1, M: 96\n",
      "1, 1, F: 56\n",
      "0, 0, M: 21\n",
      "0, 0, F: 66\n",
      "0, 1, M: 12\n",
      "0, 1, F: 21\n"
     ]
    }
   ],
   "source": [
    "print_frequencies(orb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(parent, folds, col, verbose=True):\n",
    "\n",
    "    # For each conbination of labels, prints the number of rows for each fold\n",
    "    # having this combination\n",
    "    total_errors = 0\n",
    "    n_splits = len(folds)\n",
    "    if verbose:\n",
    "        print(\"query   : #rows      : #rows per fold\\n\")\n",
    "\n",
    "    for col0 in parent[col[0]].unique():\n",
    "        for col1 in parent[col[1]].unique():\n",
    "            for col2 in parent[col[2]].unique():\n",
    "                df = parent.query(f\"{col[0]}==@col0 and {col[1]}==@col1 and {col[2]}==@col2\")\n",
    "                len_query = len(df)\n",
    "                if verbose:\n",
    "                    print(f\"{col0}, {col1}, {col2} : total = {len_query} : per fold =\", end = ' ')\n",
    "                for fold in folds:\n",
    "                    df0 = fold.query(f\"{col[0]}==@col0 and {col[1]}==@col1 and {col[2]}==@col2\")\n",
    "                    len_query_fold = len(df0)\n",
    "                    if abs(len_query_fold-len_query/n_splits) >= 2:\n",
    "                        total_errors += 1\n",
    "                    if verbose:\n",
    "                        print(f\"{len_query_fold} -\", end= ' ')\n",
    "                if verbose:\n",
    "                    print(\"\")\n",
    "\n",
    "    # Prints the statistics and the number of stratification errors\n",
    "    expected_total_length = len(parent)\n",
    "    total_length = 0\n",
    "    total_mismatches = 0\n",
    "    print(\"\\nlengths of folds : \", end = ' ')\n",
    "    for fold in folds:\n",
    "        len_fold = len(fold)\n",
    "        print(len_fold, end=' ')\n",
    "        total_length += len_fold\n",
    "        if abs(len_fold-expected_total_length/n_splits) >= 2:\n",
    "            total_mismatches += 1\n",
    "    print(f\"\\nExpected total_length = {expected_total_length}\")\n",
    "    print(f\"Effective total_length = {total_length}\")\n",
    "\n",
    "    print(f\"total number of stratification errors: {total_errors}\")\n",
    "    print(f\"total number of mismatched fold sizes : {total_mismatches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_split_through_sorting_shuffle(df, n_splits, stratify_columns, random_state):\n",
    "    \"\"\"Custom iterative train test split which\n",
    "    maintains balanced representation.\n",
    "    \"\"\"\n",
    "    # Dataframe random row shuffle + sorting according to stratify_columns\n",
    "    sorted = df.sample(frac=1, random_state=random_state).sort_values(stratify_columns)\n",
    "    # for each fold, we take one row every n_splits rows\n",
    "    folds = [sorted.iloc[i::n_splits, :] for i in range(n_splits)]\n",
    "    # Further shuffling\n",
    "    folds = [fold.sample(frac=1, random_state=random_state) for fold in folds]\n",
    "    random.Random(random_state).shuffle(folds)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = iterative_split_through_sorting_shuffle(orb, n_splits, ['Right', 'Left', 'Sex'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query   : #rows      : #rows per fold\n",
      "\n",
      "1, 0, M : total = 44 : per fold = 5 - 4 - 4 - 5 - 5 - 4 - 4 - 5 - 4 - 4 - \n",
      "1, 0, F : total = 74 : per fold = 7 - 7 - 7 - 7 - 7 - 8 - 8 - 7 - 8 - 8 - \n",
      "1, 1, M : total = 96 : per fold = 10 - 10 - 10 - 10 - 10 - 9 - 9 - 10 - 9 - 9 - \n",
      "1, 1, F : total = 56 : per fold = 5 - 6 - 6 - 5 - 5 - 6 - 6 - 5 - 6 - 6 - \n",
      "0, 0, M : total = 21 : per fold = 3 - 2 - 2 - 2 - 2 - 2 - 2 - 2 - 2 - 2 - \n",
      "0, 0, F : total = 66 : per fold = 6 - 6 - 6 - 6 - 7 - 7 - 7 - 7 - 7 - 7 - \n",
      "0, 1, M : total = 12 : per fold = 1 - 2 - 2 - 1 - 1 - 1 - 1 - 1 - 1 - 1 - \n",
      "0, 1, F : total = 21 : per fold = 2 - 2 - 2 - 3 - 2 - 2 - 2 - 2 - 2 - 2 - \n",
      "\n",
      "lengths of folds :  39 39 39 39 39 39 39 39 39 39 \n",
      "Expected total_length = 390\n",
      "Effective total_length = 390\n",
      "total number of stratification errors: 0\n",
      "total number of mismatched fold sizes : 0\n"
     ]
    }
   ],
   "source": [
    "print_results(orb, folds, ['Right', 'Left', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/neurospin/dico/data/deep_folding/current/datasets/hcp/FIP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(folds)):\n",
    "    folds[i].reset_index()['Subject'].to_csv(\n",
    "        f\"{save_path}/split_{i}.csv\",\n",
    "        header=False,\n",
    "        index=False)\n",
    "        #quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test csv\n",
    "l_tot = []\n",
    "for k in range(len(folds)-n_test_splits):\n",
    "    df = pd.read_csv(os.path.join(save_path, f'split_{k}.csv'), header=None)\n",
    "    l = df[0].tolist()\n",
    "    l_tot += l\n",
    "df = pd.DataFrame({'Subject': l_tot})\n",
    "df.to_csv(os.path.join(save_path,'union_splits.csv'), header=None, index=False) #quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orb.reset_index()\n",
    "df.columns=['Subject', 'Sex', 'Left_FIP', 'Right_FIP']\n",
    "df.to_csv('/neurospin/dico/data/deep_folding/current/datasets/hcp/FIP/FIP_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

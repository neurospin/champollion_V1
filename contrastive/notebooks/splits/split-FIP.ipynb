{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322326/3352108578.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "# from sklearn.model_selection import StratifiedGroupKFold\n",
    "import random\n",
    "import csv\n",
    "import glob\n",
    "import sklearn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.utils import (\n",
    "    _safe_indexing,\n",
    "    check_random_state,\n",
    "    indexable,\n",
    "    metadata_routing,\n",
    ")\n",
    "\n",
    "from sklearn.utils.validation import _num_samples, check_array, column_or_1d\n",
    "from sklearn.utils.multiclass import type_of_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIP\n",
    "n_splits=10\n",
    "n_test_splits = 2\n",
    "fip = pd.read_excel('/neurospin/dico/data/bv_databases/human/partially_labeled/FIP_patterns/IPS_labels_390.xlsx')\n",
    "fip = fip.dropna()\n",
    "fip.columns = ['Subject', 'Sex', 'Left', 'Right']\n",
    "fip = fip.set_index('Subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_frequencies(df):\n",
    "    for right in df['Right'].unique():\n",
    "        for left in df['Left'].unique():\n",
    "            for sex in df['Sex'].unique():\n",
    "                freq = df.query(\"Right==@right and Left==@left and Sex==@sex\")\n",
    "                print(f\"{right}, {left}, {sex}: {len(freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 0, M: 44\n",
      "1, 0, F: 74\n",
      "1, 1, M: 96\n",
      "1, 1, F: 56\n",
      "0, 0, M: 21\n",
      "0, 0, F: 66\n",
      "0, 1, M: 12\n",
      "0, 1, F: 21\n"
     ]
    }
   ],
   "source": [
    "print_frequencies(fip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(parent, folds, col, verbose=True):\n",
    "\n",
    "    # For each conbination of labels, prints the number of rows for each fold\n",
    "    # having this combination\n",
    "    total_errors = 0\n",
    "    n_splits = len(folds)\n",
    "    if verbose:\n",
    "        print(\"query   : #rows      : #rows per fold\\n\")\n",
    "\n",
    "    for col0 in parent[col[0]].unique():\n",
    "        for col1 in parent[col[1]].unique():\n",
    "            #for col2 in parent[col[2]].unique():\n",
    "            #df = parent.query(f\"{col[0]}==@col0 and {col[1]}==@col1 and {col[2]}==@col2\")\n",
    "            df = parent.query(f\"{col[0]}==@col0 and {col[1]}==@col1\")\n",
    "            len_query = len(df)\n",
    "            if verbose:\n",
    "                #print(f\"{col0}, {col1}, {col2} : total = {len_query} : per fold =\", end = ' ')\n",
    "                print(f\"{col0}, {col1} : total = {len_query} : per fold =\", end = ' ')\n",
    "            for fold in folds:\n",
    "                #df0 = fold.query(f\"{col[0]}==@col0 and {col[1]}==@col1 and {col[2]}==@col2\")\n",
    "                df0 = fold.query(f\"{col[0]}==@col0 and {col[1]}==@col1\")\n",
    "                len_query_fold = len(df0)\n",
    "                if abs(len_query_fold-len_query/n_splits) >= 2:\n",
    "                    total_errors += 1\n",
    "                if verbose:\n",
    "                    print(f\"{len_query_fold} -\", end= ' ')\n",
    "            if verbose:\n",
    "                print(\"\")\n",
    "\n",
    "    # Prints the statistics and the number of stratification errors\n",
    "    expected_total_length = len(parent)\n",
    "    total_length = 0\n",
    "    total_mismatches = 0\n",
    "    print(\"\\nlengths of folds : \", end = ' ')\n",
    "    for fold in folds:\n",
    "        len_fold = len(fold)\n",
    "        print(len_fold, end=' ')\n",
    "        total_length += len_fold\n",
    "        if abs(len_fold-expected_total_length/n_splits) >= 2:\n",
    "            total_mismatches += 1\n",
    "    print(f\"\\nExpected total_length = {expected_total_length}\")\n",
    "    print(f\"Effective total_length = {total_length}\")\n",
    "\n",
    "    print(f\"total number of stratification errors: {total_errors}\")\n",
    "    print(f\"total number of mismatched fold sizes : {total_mismatches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_split_through_sorting_shuffle(df, n_splits, stratify_columns, random_state):\n",
    "    \"\"\"Custom iterative train test split which\n",
    "    maintains balanced representation.\n",
    "    \"\"\"\n",
    "    # Dataframe random row shuffle + sorting according to stratify_columns\n",
    "    sorted = df.sample(frac=1, random_state=random_state).sort_values(stratify_columns)\n",
    "    # for each fold, we take one row every n_splits rows\n",
    "    folds = [sorted.iloc[i::n_splits, :] for i in range(n_splits)]\n",
    "    # Further shuffling\n",
    "    folds = [fold.sample(frac=1, random_state=random_state) for fold in folds]\n",
    "    random.Random(random_state).shuffle(folds)\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 : split in 5 folds, keep last for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "side = 'Left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results\n",
    "save_path = f\"/neurospin/dico/data/deep_folding/current/datasets/hcp/FIP/{side}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query   : #rows      : #rows per fold\n",
      "\n",
      "0, M : total = 65 : per fold = 13 - 13 - 13 - 13 - 13 - \n",
      "0, F : total = 140 : per fold = 28 - 28 - 28 - 28 - 28 - \n",
      "1, M : total = 108 : per fold = 22 - 22 - 22 - 21 - 21 - \n",
      "1, F : total = 77 : per fold = 15 - 15 - 15 - 16 - 16 - \n",
      "\n",
      "lengths of folds :  78 78 78 78 78 \n",
      "Expected total_length = 390\n",
      "Effective total_length = 390\n",
      "total number of stratification errors: 0\n",
      "total number of mismatched fold sizes : 0\n"
     ]
    }
   ],
   "source": [
    "n_splits=5\n",
    "results = iterative_split_through_sorting_shuffle(fip, n_splits, [side, 'Sex'], 1)\n",
    "print_results(fip, results, [side, 'Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[-1].reset_index()['Subject'].to_csv(\n",
    "    f\"{save_path}/test_split.csv\",\n",
    "    header=False,\n",
    "    index=False,\n",
    "    quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 : split remaining 80% in 5 for cross val and train eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fip_train_val = fip.drop(index=results[-1].index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query   : #rows      : #rows per fold\n",
      "\n",
      "0, M : total = 52 : per fold = 11 - 11 - 10 - 10 - 10 - \n",
      "0, F : total = 112 : per fold = 22 - 22 - 22 - 23 - 23 - \n",
      "1, M : total = 87 : per fold = 17 - 17 - 17 - 18 - 18 - \n",
      "1, F : total = 61 : per fold = 12 - 12 - 13 - 12 - 12 - \n",
      "\n",
      "lengths of folds :  62 62 62 63 63 \n",
      "Expected total_length = 312\n",
      "Effective total_length = 312\n",
      "total number of stratification errors: 0\n",
      "total number of mismatched fold sizes : 0\n"
     ]
    }
   ],
   "source": [
    "n_splits=5\n",
    "results = iterative_split_through_sorting_shuffle(fip_train_val, n_splits, [side, 'Sex'], 1)\n",
    "print_results(fip_train_val, results, [side, 'Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save folds\n",
    "for i in range(len(results)):\n",
    "    results[i].reset_index()['Subject'].to_csv(\n",
    "        f\"{save_path}/train_val_split_{i}.csv\",\n",
    "        header=False,\n",
    "        index=False,\n",
    "        quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

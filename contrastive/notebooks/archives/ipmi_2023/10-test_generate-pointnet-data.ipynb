{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test notebook to know how to process pointnet data (padding and apply transforms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from contrastive.backbones.pointnet import PointNetCls\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1114, 17, 40, 38, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(\"/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.npy\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8811440\n",
      "258607\n",
      "258607\n",
      "258607\n",
      "258607\n",
      "258607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0, ..., 340, 340, 340]),\n",
       " array([ 1,  2,  2, ..., 13, 13, 13]),\n",
       " array([15, 11, 11, ...,  8,  9, 10]),\n",
       " array([19, 15, 16, ..., 27, 26, 34]),\n",
       " array([0, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.product(data.shape))\n",
    "points = np.nonzero(data)\n",
    "for coord in points:\n",
    "    print(len(coord)) # should always be the same\n",
    "\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 833), (3, 794))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clouds = []\n",
    "\n",
    "for i in range(data.shape[0]): # loop over batch elements\n",
    "    point_cloud = np.array(data[i].nonzero()[:3])\n",
    "    clouds.append(point_cloud)\n",
    "\n",
    "clouds[0].shape, clouds[1].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_max = 1099\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "\n",
    "for point_cloud in clouds:\n",
    "    #print(len(point_cloud), len(point_cloud[0]))\n",
    "    lengths.append(point_cloud.shape[1])\n",
    "\n",
    "print(\"n_max =\", np.max(lengths))\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 893), (10, 3, 500))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = [point_cloud for i in range(10)]\n",
    "points = np.array(points)\n",
    "\n",
    "semi_points = [point_cloud[:,:500] for i in range(10)]\n",
    "semi_points = np.array(semi_points)\n",
    "\n",
    "points.shape, semi_points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 13., 13., 13.],\n",
       "          [26., 26., 29.,  ..., 11., 12., 12.],\n",
       "          [ 9., 10.,  8.,  ..., 33., 29., 30.]]]),\n",
       " tensor([[[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]],\n",
       " \n",
       "         [[ 1.,  1.,  1.,  ..., 10., 10., 10.],\n",
       "          [26., 26., 29.,  ...,  4.,  4.,  4.],\n",
       "          [ 9., 10.,  8.,  ..., 22., 23., 27.]]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.from_numpy(points).type(torch.FloatTensor)\n",
    "semi_X = torch.from_numpy(semi_points).type(torch.FloatTensor)\n",
    "X, semi_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─PointNetfeat: 1-1                      --\n",
      "|    └─STN3d: 2-1                        --\n",
      "|    |    └─Conv1d: 3-1                  256\n",
      "|    |    └─Conv1d: 3-2                  8,320\n",
      "|    |    └─Conv1d: 3-3                  132,096\n",
      "|    |    └─Linear: 3-4                  524,800\n",
      "|    |    └─Linear: 3-5                  131,328\n",
      "|    |    └─Linear: 3-6                  2,313\n",
      "|    |    └─ReLU: 3-7                    --\n",
      "|    |    └─BatchNorm1d: 3-8             128\n",
      "|    |    └─BatchNorm1d: 3-9             256\n",
      "|    |    └─BatchNorm1d: 3-10            2,048\n",
      "|    |    └─BatchNorm1d: 3-11            1,024\n",
      "|    |    └─BatchNorm1d: 3-12            512\n",
      "|    └─Conv1d: 2-2                       256\n",
      "|    └─Conv1d: 2-3                       8,320\n",
      "|    └─Conv1d: 2-4                       132,096\n",
      "|    └─BatchNorm1d: 2-5                  128\n",
      "|    └─BatchNorm1d: 2-6                  256\n",
      "|    └─BatchNorm1d: 2-7                  2,048\n",
      "├─Linear: 1-2                            524,800\n",
      "├─Linear: 1-3                            131,328\n",
      "├─Linear: 1-4                            1,028\n",
      "├─Dropout: 1-5                           --\n",
      "├─BatchNorm1d: 1-6                       1,024\n",
      "├─BatchNorm1d: 1-7                       512\n",
      "├─ReLU: 1-8                              --\n",
      "├─Sequential: 1-9                        --\n",
      "|    └─Linear: 2-8                       20\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─Linear: 2-10                      20\n",
      "=================================================================\n",
      "Total params: 1,604,917\n",
      "Trainable params: 1,604,917\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "torch.Size([10, 3, 893]) torch.Size([10, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920],\n",
       "        [-0.6124,  0.4781,  0.3671,  0.2920]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = PointNetCls(k=4)\n",
    "net.eval()\n",
    "\n",
    "summary(net)\n",
    "\n",
    "Y, trans, trans_feat = net.forward(X)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 500]) torch.Size([10, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901],\n",
       "        [-0.6122,  0.4785,  0.3655,  0.2901]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = PointNetCls(k=4)\n",
    "#net.eval()\n",
    "\n",
    "semi_Y, trans, trans_feat = net.forward(semi_X)\n",
    "\n",
    "print(semi_X.shape, semi_Y.shape)\n",
    "semi_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accept point clouds with different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/charlesq34/pointnet/issues/161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1080)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def zero_padding(cloud, n_max, shuffle=False):\n",
    "    return np.pad(cloud, ((0,0),(0,n_max-cloud.shape[1])))\n",
    "\n",
    "zero_padding(clouds[0], 1080).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1080)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repeat_padding(cloud, n_max, replace=False):\n",
    "    while n_max - cloud.shape[1] > 0: # loop in case len(cloud) < n_max/2\n",
    "        n = min(n_max - cloud.shape[1], cloud.shape[1])\n",
    "        if n < 0:\n",
    "            raise ValueError(\"the vector is too long compared to the desired vector size\")\n",
    "        \n",
    "        idx = np.random.choice(cloud.shape[1], size=n, replace=replace)\n",
    "        padded_part = cloud[:, idx]\n",
    "\n",
    "        cloud = np.concatenate([cloud, padded_part], axis=1)\n",
    "    \n",
    "    return cloud\n",
    "\n",
    "repeat_padding(clouds[0], 1080).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(clouds, padding_method=zero_padding, n_max=None):\n",
    "    if not n_max:\n",
    "        n_max = np.max([clouds[i].shape[1] for i in range(len(clouds))]) # max length of a sequence\n",
    "    padded_clouds = np.array([padding_method(cloud, n_max) for cloud in clouds])\n",
    "    return padded_clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 912), (1114, 3, 1080))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_padded_clouds = pad(clouds[:10], padding_method=zero_padding)\n",
    "r_padded_clouds = pad(clouds, padding_method=repeat_padding)\n",
    "\n",
    "z_padded_clouds.shape, r_padded_clouds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  1,  1, ...,  0,  0,  0],\n",
       "        [ 7,  8,  9, ...,  0,  0,  0],\n",
       "        [23, 23, 22, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 1,  1,  1, ...,  0,  0,  0],\n",
       "        [ 7, 13, 13, ...,  0,  0,  0],\n",
       "        [27, 16, 17, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 1,  2,  2, ...,  0,  0,  0],\n",
       "        [ 6,  5,  5, ...,  0,  0,  0],\n",
       "        [25, 23, 24, ...,  0,  0,  0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1,  1,  1, ...,  0,  0,  0],\n",
       "        [10, 10, 11, ...,  0,  0,  0],\n",
       "        [20, 21, 19, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 3,  3,  3, ...,  0,  0,  0],\n",
       "        [ 3,  9, 10, ...,  0,  0,  0],\n",
       "        [24, 15, 14, ...,  0,  0,  0]],\n",
       "\n",
       "       [[ 1,  2,  2, ...,  0,  0,  0],\n",
       "        [11,  9,  9, ...,  0,  0,  0],\n",
       "        [19, 19, 20, ...,  0,  0,  0]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_padded_clouds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1114, 3, 1080])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_padded_X = torch.from_numpy(z_padded_clouds).type(torch.FloatTensor)\n",
    "r_padded_X = torch.from_numpy(r_padded_clouds).type(torch.FloatTensor)\n",
    "z_padded_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6166,  0.4821,  0.3638,  0.2842],\n",
      "        [-0.6140,  0.4804,  0.3583,  0.2798],\n",
      "        [-0.6168,  0.4817,  0.3642,  0.2846],\n",
      "        [-0.6150,  0.4796,  0.3643,  0.2864],\n",
      "        [-0.6104,  0.4754,  0.3635,  0.2895],\n",
      "        [-0.6120,  0.4771,  0.3627,  0.2872],\n",
      "        [-0.6124,  0.4771,  0.3626,  0.2866],\n",
      "        [-0.6155,  0.4799,  0.3623,  0.2836],\n",
      "        [-0.6126,  0.4775,  0.3628,  0.2867],\n",
      "        [-0.6123,  0.4772,  0.3620,  0.2860]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6158,  0.4816,  0.3678,  0.2896],\n",
      "        [-0.6148,  0.4812,  0.3620,  0.2835],\n",
      "        [-0.6156,  0.4806,  0.3677,  0.2899],\n",
      "        [-0.6145,  0.4795,  0.3685,  0.2917],\n",
      "        [-0.6096,  0.4755,  0.3671,  0.2945],\n",
      "        [-0.6117,  0.4775,  0.3662,  0.2914],\n",
      "        [-0.6133,  0.4784,  0.3667,  0.2908],\n",
      "        [-0.6153,  0.4802,  0.3659,  0.2878],\n",
      "        [-0.6120,  0.4776,  0.3667,  0.2919],\n",
      "        [-0.6124,  0.4780,  0.3652,  0.2897]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z_Y, _, _ = net.forward(z_padded_X[:10])\n",
    "r_Y, _, _ = net.forward(r_padded_X[:10])\n",
    "print(z_Y)\n",
    "print(r_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6158,  0.4816,  0.3678,  0.2896]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6148,  0.4812,  0.3620,  0.2835]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6156,  0.4806,  0.3677,  0.2899]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6145,  0.4795,  0.3685,  0.2917]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6096,  0.4755,  0.3671,  0.2945]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6117,  0.4775,  0.3662,  0.2914]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6133,  0.4784,  0.3667,  0.2908]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6153,  0.4802,  0.3659,  0.2878]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6120,  0.4776,  0.3667,  0.2919]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.6124,  0.4780,  0.3652,  0.2897]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for cloud in clouds[:10]:\n",
    "    cloud = torch.from_numpy(cloud).type(torch.FloatTensor)\n",
    "    cloud = cloud[None,:,:]  # add a dimension\n",
    "    #print(cloud.shape)\n",
    "    print(net.forward(cloud)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion transform for pointnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired from augmentations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToPointnetTensor(object):\n",
    "\n",
    "    def __init__(self, padding_method=repeat_padding, n_max=None):\n",
    "        self.padding_method = padding_method\n",
    "        self.n_max = n_max\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        arr = tensor.numpy()\n",
    "\n",
    "        clouds = []\n",
    "        for i in range(arr.shape[0]): # loop over batch elements\n",
    "            point_cloud = np.array(arr[i].nonzero()[:3])\n",
    "            print(point_cloud.shape)\n",
    "            clouds.append(point_cloud)\n",
    "        \n",
    "        padded_clouds = pad(clouds, padding_method=self.padding_method, n_max=self.n_max)\n",
    "        \n",
    "        return torch.from_numpy(padded_clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 17, 40, 38, 1])\n",
      "(3, 912)\n",
      "(3, 711)\n",
      "(3, 799)\n",
      "(3, 702)\n",
      "(3, 636)\n",
      "(3, 659)\n",
      "(3, 775)\n",
      "(3, 897)\n",
      "(3, 836)\n",
      "(3, 767)\n",
      "(3, 874)\n",
      "(3, 906)\n",
      "(3, 923)\n",
      "(3, 721)\n",
      "(3, 803)\n",
      "(3, 609)\n",
      "(3, 854)\n",
      "(3, 844)\n",
      "(3, 870)\n",
      "(3, 677)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 3, 923])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertisseur = ToPointnetTensor(n_max=None)\n",
    "\n",
    "X = torch.from_numpy(data[:20])\n",
    "print(X.size())\n",
    "\n",
    "convertisseur(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15775, 5])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(X, as_tuple=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 912)\n",
      "(3, 711)\n",
      "(3, 799)\n",
      "(3, 702)\n",
      "(3, 636)\n",
      "(3, 659)\n",
      "(3, 775)\n",
      "(3, 897)\n",
      "(3, 836)\n",
      "(3, 767)\n",
      "(3, 874)\n",
      "(3, 906)\n",
      "(3, 923)\n",
      "(3, 721)\n",
      "(3, 803)\n",
      "(3, 609)\n",
      "(3, 854)\n",
      "(3, 844)\n",
      "(3, 870)\n",
      "(3, 677)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(np.array(data[i].nonzero()[:3]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastive Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive.data.transforms import transform_no_foldlabel\n",
    "from contrastive.data.datasets import ContrastiveDataset\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkpoint_dir': '../../Output',\n",
       " 'pickle_normal': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.pkl',\n",
       " 'numpy_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.npy',\n",
       " 'subjects_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton_subject.csv',\n",
       " 'foldlabel_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rlabel.npy',\n",
       " 'subjects_foldlabel_all': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rlabel_subject.csv',\n",
       " 'pickle_benchmark': 'null',\n",
       " 'train_val_csv_file': '/neurospin/dico/data/deep_folding/papers/midl2022/HCP_half_1bis.csv',\n",
       " 'nb_subjects': '-1',\n",
       " 'model': 'SimCLR',\n",
       " 'with_labels': 'false',\n",
       " 'input_size': '(1, 17, 40, 38)',\n",
       " 'temperature_initial': '0.5',\n",
       " 'temperature': '0.5',\n",
       " 'sigma': '5',\n",
       " 'drop_rate': '0.15',\n",
       " 'depth_decoder': '3',\n",
       " 'test': 'false',\n",
       " 'mode': 'encoder',\n",
       " 'foldlabel': 'false',\n",
       " 'fill_value': '0',\n",
       " 'patch_size': ['1', '9', '22', '21'],\n",
       " 'max_angle': '10',\n",
       " 'checkerboard_size': '4',\n",
       " 'keep_bottom': 'true',\n",
       " 'backbone_name': 'convnet',\n",
       " 'encoder_depth': '3',\n",
       " 'num_representation_features': '12',\n",
       " 'num_outputs': '30',\n",
       " 'projection_head_dims': 'null',\n",
       " 'device': 'cuda',\n",
       " 'num_cpu_workers': '16',\n",
       " 'environment': 'not_brainvisa',\n",
       " 'batch_size': '16',\n",
       " 'pin_mem': 'true',\n",
       " 'partition': ['0.9', '0.1'],\n",
       " 'lr': '0.0004',\n",
       " 'weight_decay': '5.0e-05',\n",
       " 'max_epochs': '20',\n",
       " 'nb_epochs_per_saving': '1',\n",
       " 'nb_epochs_per_tSNE': '50',\n",
       " 'nb_steps_per_flush_logs': '1',\n",
       " 'log_every_n_steps': '2',\n",
       " 'early_stopping_patience': '100',\n",
       " 'seed': '1',\n",
       " 'start_epoch': '0',\n",
       " 'checkpoint_path': 'null',\n",
       " 'analysis_path': 'null',\n",
       " 'verbose': '1',\n",
       " 'classifier_name': 'svm',\n",
       " 'training_embeddings': '/neurospin/dico/agaudin/Runs/03_monkeys/Output/analysis_folders/pca/30/Run1/pca_embeddings.csv',\n",
       " 'embeddings_of_interest': 'null',\n",
       " 'results_save_path': 'null',\n",
       " 'training_labels': '/neurospin/dico/data/bv_databases/human/partially_labeled/ACCpatterns/all.csv',\n",
       " 'labels_of_interest': 'null',\n",
       " 'class_max_epochs': '5000',\n",
       " 'n_repeat': '250',\n",
       " 'classifier_seed': '24',\n",
       " 'classifier_test_size': '0.2',\n",
       " 'model_path': '/neurospin/dico/agaudin/Runs/04_pointnet/Output/2022-08-02/aymeric_dense_T=0.5(2)',\n",
       " 'embeddings_save_path': '/neurospin/dico/agaudin/Runs/04_pointnet/Output/2022-08-02/aymeric_dense_T=0.5(2)/cingulate_ACCpatterns_embeddings',\n",
       " 'pca_Xfit': '/neurospin/dico/data/deep_folding/current/datasets/hcp/crops/2mm/CINGULATE/mask/Rskeleton.npy',\n",
       " 'pca_Xtransform': '/neurospin/dico/data/deep_folding/current/datasets/ACCpatterns/crops/2mm/CINGULATE/mask/Rskeleton.npy',\n",
       " 'n_pca': '30'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/neurospin/dico/agaudin/Runs/04_pointnet/Output/2022-08-04/15-21-29/.hydra/config.yaml\", 'r') as file:    \n",
    "    config = yaml.load(file, Loader=yaml.BaseLoader)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'backbone_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-339492d9b525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform_no_foldlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/neurospin/dico/agaudin/Runs/04_pointnet/2022_jchavas_cingulate_inhibitory_control/contrastive/data/transforms.py\u001b[0m in \u001b[0;36mtransform_no_foldlabel\u001b[0;34m(from_skeleton, config)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_no_foldlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_skeleton\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'pointnet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             transforms.Compose([\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'backbone_name'"
     ]
    }
   ],
   "source": [
    "transform_no_foldlabel(True, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv_local': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29d17951836d0959caaf0c9cd10ee54c4ed7100b51f8cf6fe8a170600c2ce0e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
